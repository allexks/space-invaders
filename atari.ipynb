{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2wsuq_uaCwE"
      },
      "source": [
        "# Space Invaders"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies"
      ],
      "metadata": {
        "id": "8J9pbywRcrR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.9.1 gym keras-rl2 gym[atari]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hoe-hREJaEfO",
        "outputId": "aa210d0b-02f6-4143-8baa-fc4290b04457"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow==2.9.1 in /usr/local/lib/python3.7/dist-packages (2.9.1)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: keras-rl2 in /usr/local/lib/python3.7/dist-packages (1.0.5)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (2.9.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (2.10.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (0.3.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (0.2.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (2.9.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (1.0.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (14.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (57.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (1.14.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (3.17.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (1.6.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (1.21.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (1.46.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (0.26.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (2.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (1.12)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (4.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.1) (21.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow==2.9.1) (0.37.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.3.7)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.2.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (0.2.9)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gym) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gym) (7.1.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow==2.9.1) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROM instructions: https://github.com/openai/atari-py#roms"
      ],
      "metadata": {
        "id": "NPjXbngKZAX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m atari_py.import_roms roms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4iIN1BQZOGp",
        "outputId": "2550265a-2d5b-4d25-ee76-2defcb0c06bb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "copying space_invaders.bin from roms/Space Invaders.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/space_invaders.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploration and baseline"
      ],
      "metadata": {
        "id": "gS96fFQKcf86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import random\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "7B2KcFLmcn6e"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"SpaceInvaders-v4\")\n",
        "print(env.observation_space.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y074RXzxc1v7",
        "outputId": "7367f699-488e-4dca-9222-561cab6652a8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(210, 160, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.unwrapped.get_action_meanings()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEd_Sh4nZfQU",
        "outputId": "1ae5cbcd-5e72-4cfd-f5cb-b134d56a9027"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPISODES = 100\n",
        "scores = []\n",
        "for episode in range(1, EPISODES + 1):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    score = 0 \n",
        "    \n",
        "    while not done:\n",
        "        # env.render()\n",
        "        action = random.choice(range(env.action_space.n))\n",
        "        n_state, reward, done, info = env.step(action)\n",
        "        score += reward\n",
        "    \n",
        "    scores.append(score)\n",
        "    print(f\"Episode {episode}: Reward == {score}\")\n",
        "\n",
        "avg = np.mean(scores)\n",
        "print(f\"Average reward: {avg}\")\n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvgmfMu-Z3HG",
        "outputId": "d1c2abe7-c0da-4f46-a954-bb934376a05b"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1: Reward == 105.0\n",
            "Episode 2: Reward == 110.0\n",
            "Episode 3: Reward == 210.0\n",
            "Episode 4: Reward == 265.0\n",
            "Episode 5: Reward == 110.0\n",
            "Episode 6: Reward == 45.0\n",
            "Episode 7: Reward == 35.0\n",
            "Episode 8: Reward == 180.0\n",
            "Episode 9: Reward == 210.0\n",
            "Episode 10: Reward == 315.0\n",
            "Episode 11: Reward == 110.0\n",
            "Episode 12: Reward == 120.0\n",
            "Episode 13: Reward == 110.0\n",
            "Episode 14: Reward == 215.0\n",
            "Episode 15: Reward == 105.0\n",
            "Episode 16: Reward == 335.0\n",
            "Episode 17: Reward == 180.0\n",
            "Episode 18: Reward == 360.0\n",
            "Episode 19: Reward == 155.0\n",
            "Episode 20: Reward == 125.0\n",
            "Episode 21: Reward == 65.0\n",
            "Episode 22: Reward == 125.0\n",
            "Episode 23: Reward == 110.0\n",
            "Episode 24: Reward == 105.0\n",
            "Episode 25: Reward == 80.0\n",
            "Episode 26: Reward == 120.0\n",
            "Episode 27: Reward == 155.0\n",
            "Episode 28: Reward == 115.0\n",
            "Episode 29: Reward == 35.0\n",
            "Episode 30: Reward == 35.0\n",
            "Episode 31: Reward == 185.0\n",
            "Episode 32: Reward == 105.0\n",
            "Episode 33: Reward == 55.0\n",
            "Episode 34: Reward == 60.0\n",
            "Episode 35: Reward == 75.0\n",
            "Episode 36: Reward == 135.0\n",
            "Episode 37: Reward == 105.0\n",
            "Episode 38: Reward == 155.0\n",
            "Episode 39: Reward == 75.0\n",
            "Episode 40: Reward == 50.0\n",
            "Episode 41: Reward == 65.0\n",
            "Episode 42: Reward == 120.0\n",
            "Episode 43: Reward == 75.0\n",
            "Episode 44: Reward == 50.0\n",
            "Episode 45: Reward == 180.0\n",
            "Episode 46: Reward == 80.0\n",
            "Episode 47: Reward == 115.0\n",
            "Episode 48: Reward == 215.0\n",
            "Episode 49: Reward == 150.0\n",
            "Episode 50: Reward == 275.0\n",
            "Episode 51: Reward == 310.0\n",
            "Episode 52: Reward == 210.0\n",
            "Episode 53: Reward == 135.0\n",
            "Episode 54: Reward == 90.0\n",
            "Episode 55: Reward == 215.0\n",
            "Episode 56: Reward == 55.0\n",
            "Episode 57: Reward == 135.0\n",
            "Episode 58: Reward == 150.0\n",
            "Episode 59: Reward == 155.0\n",
            "Episode 60: Reward == 65.0\n",
            "Episode 61: Reward == 90.0\n",
            "Episode 62: Reward == 125.0\n",
            "Episode 63: Reward == 105.0\n",
            "Episode 64: Reward == 5.0\n",
            "Episode 65: Reward == 150.0\n",
            "Episode 66: Reward == 35.0\n",
            "Episode 67: Reward == 140.0\n",
            "Episode 68: Reward == 105.0\n",
            "Episode 69: Reward == 120.0\n",
            "Episode 70: Reward == 50.0\n",
            "Episode 71: Reward == 440.0\n",
            "Episode 72: Reward == 145.0\n",
            "Episode 73: Reward == 15.0\n",
            "Episode 74: Reward == 140.0\n",
            "Episode 75: Reward == 70.0\n",
            "Episode 76: Reward == 35.0\n",
            "Episode 77: Reward == 55.0\n",
            "Episode 78: Reward == 255.0\n",
            "Episode 79: Reward == 215.0\n",
            "Episode 80: Reward == 210.0\n",
            "Episode 81: Reward == 210.0\n",
            "Episode 82: Reward == 145.0\n",
            "Episode 83: Reward == 35.0\n",
            "Episode 84: Reward == 445.0\n",
            "Episode 85: Reward == 65.0\n",
            "Episode 86: Reward == 20.0\n",
            "Episode 87: Reward == 120.0\n",
            "Episode 88: Reward == 410.0\n",
            "Episode 89: Reward == 60.0\n",
            "Episode 90: Reward == 275.0\n",
            "Episode 91: Reward == 80.0\n",
            "Episode 92: Reward == 105.0\n",
            "Episode 93: Reward == 35.0\n",
            "Episode 94: Reward == 180.0\n",
            "Episode 95: Reward == 190.0\n",
            "Episode 96: Reward == 210.0\n",
            "Episode 97: Reward == 210.0\n",
            "Episode 98: Reward == 50.0\n",
            "Episode 99: Reward == 180.0\n",
            "Episode 100: Reward == 155.0\n",
            "Average reward: 138.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the baseline is around 150."
      ],
      "metadata": {
        "id": "q7VwVGfhc-p4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "KTzMWfxFdDrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Convolution2D, Resizing, Rescaling\n",
        "from tensorflow.python.keras.layers.core import Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.image import rgb_to_grayscale"
      ],
      "metadata": {
        "id": "MFF_4nRjdJOy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(height, width, channels, actions):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(height, width, channels)))\n",
        "    model.add(Lambda(rgb_to_grayscale))\n",
        "    model.add(Resizing(height // 2, width // 2))\n",
        "    model.add(Rescaling(1./255)) # normalize to [0, 1]\n",
        "    model.add(Convolution2D(32, (8,8), strides=(4,4), activation='relu'))\n",
        "    model.add(Convolution2D(64, (4,4), strides=(2,2), activation='relu'))\n",
        "    model.add(Convolution2D(64, (3,3), activation='relu'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    # model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dense(actions, activation='linear'))\n",
        "    return model"
      ],
      "metadata": {
        "id": "_QXMNUladM_T"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "height, width, channels = env.observation_space.shape\n",
        "actions = env.action_space.n"
      ],
      "metadata": {
        "id": "6rdDUGF1dgVE"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(height, width, channels, actions)"
      ],
      "metadata": {
        "id": "t2YjqWDYdSp5"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZ_R6xoWdolT",
        "outputId": "ff1b4ff8-f7a6-434e-8d32-26a80c777c2c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " module_wrapper_3 (ModuleWra  (None, 210, 160, 1)      0         \n",
            " pper)                                                           \n",
            "                                                                 \n",
            " resizing_3 (Resizing)       (None, 105, 80, 1)        0         \n",
            "                                                                 \n",
            " rescaling_3 (Rescaling)     (None, 105, 80, 1)        0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 25, 19, 32)        2080      \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 11, 8, 64)         32832     \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 9, 6, 64)          36928     \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 3456)              0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 512)               1769984   \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 6)                 3078      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,844,902\n",
            "Trainable params: 1,844,902\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent"
      ],
      "metadata": {
        "id": "m9i95BBkdzhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rl.agents import DQNAgent\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy"
      ],
      "metadata": {
        "id": "FjrTen__d3Ip"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_agent(model, actions):\n",
        "    policy = LinearAnnealedPolicy(\n",
        "        EpsGreedyQPolicy(), \n",
        "        attr='eps', \n",
        "        value_max=1.0, \n",
        "        value_min=0.1, \n",
        "        value_test=0.2, \n",
        "        nb_steps=10000\n",
        "    )\n",
        "    memory = SequentialMemory(\n",
        "        limit=1000, \n",
        "        window_length=3\n",
        "    )\n",
        "    dqn = DQNAgent(\n",
        "        model=model, \n",
        "        memory=memory, \n",
        "        policy=policy,\n",
        "        enable_dueling_network=True, \n",
        "        dueling_type='avg', \n",
        "        nb_actions=actions, \n",
        "        nb_steps_warmup=1000\n",
        "    )\n",
        "    return dqn"
      ],
      "metadata": {
        "id": "un0NM5Cee05L"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dqn = build_agent(model, actions)\n",
        "dqn.compile(Adam(lr=1e-4))"
      ],
      "metadata": {
        "id": "XCK4WyX1f1VF",
        "outputId": "f5c9f648-b8b3-4786-f7d1-1dccbe96d1f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-bd3e293acfdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdqn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/rl/agents/dqn.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, metrics)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;31m# We never train the target model, hence we can set the optimizer and loss arbitrarily.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_model_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/rl/util.py\u001b[0m in \u001b[0;36mclone_model\u001b[0;34m(model, custom_objects)\u001b[0m\n\u001b[1;32m     11\u001b[0m     config = {\n\u001b[1;32m     12\u001b[0m         \u001b[0;34m'class_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;34m'config'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     }\n\u001b[1;32m     15\u001b[0m     \u001b[0mclone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_network_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_validate_graph_inputs_and_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mget_network_config\u001b[0;34m(network, serialize_layer_fn)\u001b[0m\n\u001b[1;32m   1382\u001b[0m           \u001b[0mfiltered_inbound_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0mlayer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserialize_layer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m       \u001b[0mlayer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m       \u001b[0mlayer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inbound_nodes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_inbound_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mserialize_keras_object\u001b[0;34m(instance)\u001b[0m\n\u001b[1;32m    509\u001b[0m         return serialize_keras_class_and_config(\n\u001b[1;32m    510\u001b[0m             name, {_LAYER_UNDEFINED_CONFIG_KEY: True})\n\u001b[0;32m--> 511\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m     \u001b[0mserialization_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mserialize_keras_object\u001b[0;34m(instance)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_registered_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m       \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_SKIP_FAILED_SERIALIZATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer_v1.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;31m# or that `get_config` has been overridden:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_args\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_is_default'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m       raise NotImplementedError('Layers with arguments in `__init__` must '\n\u001b[0m\u001b[1;32m    496\u001b[0m                                 'override `get_config`.')\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: Layers with arguments in `__init__` must override `get_config`."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "rTFv2KMAimBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dqn.fit(env, nb_steps=10000, visualize=False, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOP8OrohiUj6",
        "outputId": "913dfa5c-ed7b-4feb-dd73-6cbfdb70916d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 10000 steps ...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training_v1.py:2070: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "  703/10000: episode: 1, duration: 26.704s, episode steps: 703, steps per second:  26, episode reward: 45.000, mean reward:  0.064 [ 0.000, 15.000], mean action: 2.563 [0.000, 5.000],  loss: --, mean_q: --, mean_eps: --\n",
            " 1372/10000: episode: 2, duration: 666.274s, episode steps: 669, steps per second:   1, episode reward: 100.000, mean reward:  0.149 [ 0.000, 20.000], mean action: 2.508 [0.000, 5.000],  loss: 9.782588, mean_q: 6.822987, mean_eps: 0.893260\n",
            " 2402/10000: episode: 3, duration: 1772.951s, episode steps: 1030, steps per second:   1, episode reward: 380.000, mean reward:  0.369 [ 0.000, 200.000], mean action: 2.488 [0.000, 5.000],  loss: 6.755573, mean_q: 7.143362, mean_eps: 0.830215\n",
            " 3062/10000: episode: 4, duration: 1135.876s, episode steps: 660, steps per second:   1, episode reward: 110.000, mean reward:  0.167 [ 0.000, 30.000], mean action: 2.586 [0.000, 5.000],  loss: 3.504639, mean_q: 7.140533, mean_eps: 0.754165\n",
            " 3699/10000: episode: 5, duration: 1182.872s, episode steps: 637, steps per second:   1, episode reward: 125.000, mean reward:  0.196 [ 0.000, 30.000], mean action: 2.491 [0.000, 5.000],  loss: 0.446724, mean_q: 5.877246, mean_eps: 0.695800\n",
            " 4704/10000: episode: 6, duration: 1891.159s, episode steps: 1005, steps per second:   1, episode reward: 240.000, mean reward:  0.239 [ 0.000, 30.000], mean action: 2.518 [0.000, 5.000],  loss: 0.530473, mean_q: 6.404538, mean_eps: 0.621910\n",
            " 5576/10000: episode: 7, duration: 1575.535s, episode steps: 872, steps per second:   1, episode reward: 215.000, mean reward:  0.247 [ 0.000, 30.000], mean action: 2.417 [0.000, 5.000],  loss: 0.487392, mean_q: 6.916710, mean_eps: 0.537445\n",
            " 6140/10000: episode: 8, duration: 1015.911s, episode steps: 564, steps per second:   1, episode reward: 100.000, mean reward:  0.177 [ 0.000, 20.000], mean action: 2.128 [0.000, 5.000],  loss: 0.337325, mean_q: 5.828970, mean_eps: 0.472825\n",
            " 7231/10000: episode: 9, duration: 1926.362s, episode steps: 1091, steps per second:   1, episode reward: 210.000, mean reward:  0.192 [ 0.000, 30.000], mean action: 2.685 [0.000, 5.000],  loss: 0.404974, mean_q: 5.928021, mean_eps: 0.398350\n",
            " 8050/10000: episode: 10, duration: 1446.387s, episode steps: 819, steps per second:   1, episode reward: 220.000, mean reward:  0.269 [ 0.000, 30.000], mean action: 2.893 [0.000, 5.000],  loss: 0.367218, mean_q: 5.728740, mean_eps: 0.312400\n",
            " 8853/10000: episode: 11, duration: 1409.987s, episode steps: 803, steps per second:   1, episode reward: 205.000, mean reward:  0.255 [ 0.000, 25.000], mean action: 2.695 [0.000, 5.000],  loss: 0.448761, mean_q: 5.866341, mean_eps: 0.239410\n",
            " 9705/10000: episode: 12, duration: 1538.350s, episode steps: 852, steps per second:   1, episode reward: 155.000, mean reward:  0.182 [ 0.000, 25.000], mean action: 2.616 [0.000, 5.000],  loss: 0.225643, mean_q: 5.798450, mean_eps: 0.164935\n",
            "done, took 16100.318 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe05c107f90>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = dqn.test(env, nb_episodes=20, visualize=False)\n",
        "np.mean(scores.history[\"episode_reward\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxnlZ2DdqMmO",
        "outputId": "d4a5c8dd-78db-46a7-b06e-e1d349a15d47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 90.000, steps: 442\n",
            "Episode 2: reward: 100.000, steps: 683\n",
            "Episode 3: reward: 135.000, steps: 498\n",
            "Episode 4: reward: 105.000, steps: 559\n",
            "Episode 5: reward: 195.000, steps: 929\n",
            "Episode 6: reward: 235.000, steps: 922\n",
            "Episode 7: reward: 20.000, steps: 380\n",
            "Episode 8: reward: 75.000, steps: 437\n",
            "Episode 9: reward: 80.000, steps: 501\n",
            "Episode 10: reward: 165.000, steps: 663\n",
            "Episode 11: reward: 105.000, steps: 605\n",
            "Episode 12: reward: 135.000, steps: 582\n",
            "Episode 13: reward: 55.000, steps: 458\n",
            "Episode 14: reward: 60.000, steps: 680\n",
            "Episode 15: reward: 105.000, steps: 711\n",
            "Episode 16: reward: 105.000, steps: 509\n",
            "Episode 17: reward: 170.000, steps: 924\n",
            "Episode 18: reward: 160.000, steps: 700\n",
            "Episode 19: reward: 220.000, steps: 1154\n",
            "Episode 20: reward: 50.000, steps: 380\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "118.25"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "atari.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}